{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/annamalaisenthil112/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /home/annamalaisenthil112/.keras-ocr/crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint_text(img_path, pipeline,s):\n",
    "    # read image\n",
    "    img = keras_ocr.tools.read(img_path)\n",
    "    # generate (word, box) tuples \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    recognized_text = []\n",
    "    # sorted_boxes = sorted(prediction_groups[0], key=lambda x: (x[1][0][1], midpoint(x[1][0][0], x[1][0][1], x[1][2][0], x[1][2][1]), x[1][0][0]))\n",
    "    for box in prediction_groups[0]:\n",
    "        recognized_text.append(box[0])\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    c=0\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        c+=1\n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mod_image_path=\"./data/img_copy/\"+s+\".png\"\n",
    "    with open (\"image_text\",\"a\") as fh:\n",
    "        fh.write(str(recognized_text)+\"\\n\")\n",
    "    cv2.imwrite(mod_image_path,img_rgb)\n",
    "    return(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# path=\"./data/img/01245.png\"\n",
    "# img=inpaint_text(path,pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Judging the sentiment in the text\n",
    "# from textblob import TextBlob\n",
    "# from textblob.sentiments import NaiveBayesAnalyzer,PatternAnalyzer \n",
    "# def tester(text):\n",
    "#     return TextBlob(text,analyzer=PatternAnalyzer()).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6999999999999998\n"
     ]
    }
   ],
   "source": [
    "# text=\"i am bad not\"\n",
    "# tester(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "2\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "4\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "1/1 [==============================] - 1s 829ms/step\n",
      "5\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 671ms/step\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open (\"image_text\",\"w\") as fh:\n",
    "    pass\n",
    "file_path = \"./data/trial.jsonl\"\n",
    "c=0\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        c+=1\n",
    "        print(c)\n",
    "        data_dict = json.loads(line)\n",
    "        # print(data_dict)\n",
    "        v=data_dict['id']\n",
    "        image_path = \"./data/img/\"  # Replace with the actual path to your image\n",
    "        s=str(v)\n",
    "        if(len(s)==4):\n",
    "            s='0'+s\n",
    "        image_path+=s\n",
    "        image_path+=\".png\"\n",
    "        img=inpaint_text(image_path,pipeline,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the previous code to judge if there is any change in detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
